<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F15%2FPHP%E6%95%B0%E7%BB%84%E7%BB%93%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%2F</url>
    <content type="text"><![CDATA[一. PHP数组结构的演变这个地方主要讲PHP5.6=&gt;PHP7.0=&gt;PHP7.1的演变过程 我们可以看到，数组本质就是一个hashtable结构，左侧的0~nTablemask便是hash下标，而后面有一个双向链表，便是我们通常所说的hash冲突的链地址法。 而绿色的双向链表，则是foreach遍历用的，这个地方用双向链表，主要是为了逆序访问来用的，遍历的时候，就是从pListHead开始不断的next便可以遍历所有的元素。这样要比下标遍历hashtable快得多。 但是这个结构有很明显的缺点： ①. 每次插入/删除元素都要申请/释放内存，这样会严重的导致内存碎片化，降低内存的使用率。 ②. 再者，每次插入元素的时候都要去申请内存，会有一次寻址的过程，时间效率低。 ③. 指针结构很复杂，有大量的指针操作。 针对上面5.6所有的问题，提出了如上的结构。arData结构便是我们插入数据的结构，是一段连续的内存，在初始化/数组扩充时一次性内存申请好，这样内存便不会产生碎片化问题，并且我们看，hash冲突的时候是单链表，并且没有插入元素时候的双向链表，因为我们可以直接扫描数组便可以顺序/逆序访问插入的数据。 如上是最新的数据结构，最主要的区别是把7.0的两段内存转化为一段内存，算是在内存上的继续优化。他的内存申请是从下标-8位置申请的，然后移动指针到key1位置。 二. PHP7.0数组源码实现3.1 PHP7.0数组的主要数据结构 Bucket结构便是我们所说的保存插入数据的结构。主要包括：key(字符串，如果是数字下标，转化位字符串), value, h(只会计算一次，如果是数组下标，直接把key作为h)。 这便是PHP7.0的数组结构，我后面讲全部是用7.0结构讲，比较清晰。nNextFreeElement是无key值存储时使用的数据，用来分配key值。 3.2 PHP数组的hash方法 如上是php的hash源码，看一眼容易把人瞎蒙，然而把它简化一下便是： 简单讲一下。其中源码中把 hash*33 转化为 (hash&lt;&lt;5) + hash 在一个就是，使用了循环展开策略，减少不必要的循环判断，在一个是连续的执行相同的指令，提高指令的cache命中率。可以看着：https://en.wikipedia.org/wiki/Loop_unrolling 那么计算出hash值来之后，并不是我们想要的下标，因为很有可能超过了hashmask值，所以需要一步计算来得到index。 •7.0： hashmask = tablesize – 1; //tablesize一定是2的指数倍，和申请内存有关系，后面讲 h = hashcode &amp; hashmask; //计算index hashmask=7(10)=111(2) //十进制下的7转为二进制下的111 0&lt;=h&lt;8 //所有值 &amp; hashmask 一定在0~7之间 •7.1： hashmask = -tablesize; h = hashcode | hashmask; hashmask=-8(10)=11111000(2补码) -8&lt;=h&lt;=-1 7.1的结构因为是hash负下标，所以用的另一种计算策略，大同小异。 3.3 PHP数组插入数据 大致流程如上，看一下就好。讲一下插入数据的结构变化。 在我们插入key6这个key值之后，在arData数据往后排，我们假设他与key1的hash冲突，所以使用链地址法，直接插入到链表首部。 3.4 PHP数组删除数据在上面的结构，假如我们删除key1，会有两种考虑。 ①. 删除该元素之后，我们是否要保证空间的利用率，把后面的数据移动，覆盖当前位置。 ②. 删除元素之后，直接把该位置空出。 其实第一种策略是不可接受，因为这样会导致时间复杂度退化为O(n)，而第二种策略，我们控制当前位置之后，我们可以在内存扩充时，把这些空位置给删除掉即可。 3.4 PHP数组内存申请及rehash假设我们要在如下结构中插入key9 发现当前arData已经满了，所以我们申请新内存(初始大小位2，以2的倍数不断扩充)，把所有数据以内存的形式copy过去，然后扫描数组，把无用的数据给删除掉(用移动后面元素的策略)。因为nTableMask数值改变了然后进行rehash。 这里有一个点值得提一下：把原数据copy过去的时候，我们可以选择遍历原先的数组，把有用的数据copy过去，也可以先把原内存的数据复制到新内存的位置，然后去遍历数组去移动数据。PHP实现选择了第二种，这样考虑应该是我们删除元素的次数比较少，直接以内存的形式copy数据要比遍历copy的速度快，在权衡之下选择了第二种。 结构变化如上图。 四. PHP数组的可优化点4.1 PHP数组的退化案例本案例参考的鸟哥的博客。 大概测了一下 我们可以看到，时间效率差别很大。我们来分析一下为什么会这样。 •插入元素:key=0,165536,265536,….,65535*65536 •插入元素特点:h=key&amp;65535=0,生成绝对的hash冲突导致退化1*00000000&amp;0**011111111=0 •大致的插入计算次数：1+2+3+4+5+…+65536(每次插入都会冲突，从而会去查询是否有相同的key值，所以会有扫描的次数总和如此) •导致插入元素时间复杂度退化为O(n*(1+n)/2)=O(n^2) 那么65536^2在计算机1s处理10^8运算的情况下，大概36s以上，所以运行结果算是可预期的。 4.2 可进行优化的策略我们参考Java中hashtable的实现来使用红黑树解决这个问题。 •①.设定链表冲突长度的阀值 •②.当链表长度超过阀值的时候，以key值为键值进行红黑树的转化，key全是字符串，所以我们可以以key的字典序进行排序 •③.Hashtable的指针指向树根 •④.增删查改，不断对红黑树结构进行调整 •⑤.使增删查改时间复杂度达到最差为O(logn) 我们来看下结构的变化为： 如果不了解红黑树，可以去参考一下《算法导论》中的详解 链接：https://www.jianshu.com/p/3f1d0f9907a1]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F15%2FMySQL%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8CMVCC%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F15%2FBitMap%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Kafka 原理详解]]></title>
    <url>%2F2018%2F10%2F04%2FKafka%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Kafka 是一个java开发的mq中间件，依赖于zookeper，有高可用，高吞吐量等特点。 优势 可靠性：partition机制和replication机制，使消息的传递有着很高的可靠性 稳定性，支持集群 高性能，高吞吐量，即使在TB的数据存储情况下，仍然表现出很好的稳定性 支持消息广播和单播，可以根据重设offset实现消息的重复消费 角色 Broker：kafka集群由一个或多个kafka server组成，每个server即Broker。 Topic：逻辑概念。kafka对消息保存时根据Topic进行归类，一个Topic可以认为是一类消息。 Partition：物理概念。每个topic将被分成一到多个partition（分区），每个partition在存储层面就是一个append log文件。一个非常大的topic可以分成多个partition，分布到多个broker上。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。 offset：任何发布到Partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量），offset为一个long型数字，它是唯一标记一条消息。kafka并没有提供其他额外的索引机制来存储offset，因此在kafka中几乎不允许对消息进行“随机读写”。 Producer：生成者。Producer将消息发布到指定的Topic，也可以指定Partition。 Consumer：消费者。Consumer采用pull的形式从Producer拉取消息 Consumer Group：每个 consumer 属于一个特定的 consumer group（若不指定 group name 则属于默认的 group）。一个 topic可以有多个CG，topic的消息会分发到所有的CG，但每个CG只会把消息发给该CG中的一个 consumer。如果所有的consumer都具有相同的group, 即单播，消息将会在consumers之间负载均衡；如果所有的consumer都具有不同的group，那这就是”发布-订阅”，每条消息将会广播给所有的consumer。 分区机制和文件存储机制 如图，kafka中的消息是以topic进行分类的，生产者通过topic向kafka broker发送消息，消费者通过topic读取消息。然而topic在物理层面上又能够以partition进行分组，同一个topic下有多个不同的partition，每个partiton在物理上对应一个目录（文件夹），以topic名称+有序序号的形式命名（序号从0开始计，最大为partition数-1）。partition是实际物理上的概念，而topic是逻辑上的概念。Patition 的设计使得Kafka的吞吐率可以水平扩展。 每个分区文件夹下存储这个分区的所有消息(.log)和索引文件(.index)。“.index”索引文件存储大量的元数据，“.log”数据文件存储大量的消息，索引文件中的元数据指向对应数据文件中message的物理偏移地址。其中以“.index”索引文件中的元数据[3, 348]为例，在“.log”数据文件表示第3个消息，即在全局partition中表示170410+3=170413个消息，该消息的物理偏移地址为348。 那么如何从partition中通过offset查找message呢?以上图为例，读取offset=170418的消息，首先查找segment文件，其中 00000000000000000000.index为最开始的文件，第二个文件为00000000000000170410.index(起始偏移为170410+1=170411)，而第 三个文件为00000000000000239430.index(起始偏移为239430+1=239431)，所以这个offset=170418就落到了第二个文件之中。其他 后续文件可以依次类推，以其实偏移量命名并排列这些文件，然后根据二分查找法就可以快速定位到具体文件位置。其次根据 00000000000000170410.index文件中的[8,1325]定位到00000000000000170410.log文件中的1325的位置进行读取。 Kafka中topic的每个partition有一个预写式的日志文件，虽然partition可以继续细分为若干个segment文件，但是对于上层应用来说可以将 partition看成最小的存储单元(一个有多个segment文件拼接的“巨型”文件)，每个partition都由一些列有序的、不可变的消息组成，这些消息被连续的追加到partition中。 那如何保证消息均匀的分布到不同的partition中？生产者在生产数据的时候，可以为每条消息指定Key，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个分区中，如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。分区规则可以自定义，比如将消息的key做了hashcode，然后和分区数（numPartitions）做模运算，使得每一个key都可以分布到一个分区中。 高可用（High availability）kafka的高可用就是依赖于上面的文件存储结构的，kafka能保证HA的策略有 data replication和leader election。 leader 机制为了提高消息的可靠性，Kafka每个topic的partition有N个副本(replicas)，其中N(大于等于1)是topic的复制因子(replica fator)的个数。这个时候每个 partition下面就有可能有多个 replica（replication机制，相当于是partition的副本但是有可能存储在其他的broker上）,但是这多个replica并不一定分布在一个broker上，而这时候为了更好的在replica之间复制数据，此时会选出一个leader，这个时候 producer会push消息到这个leader（leader机制），consumer也会从这个leader pull 消息，其他的 replica只是作为follower从leader复制数据，leader负责所有的读写；如果没有一个leader的话，所有的follower都去进行读写 那么NxN(N+1个replica之间复制消息)的互相同步数据就变得很复杂而且数据的一致性和有序性不能够保证。 如何将所有Replica均匀分布到整个集群为了实现更高的可用性，推荐在部署kafka的时候，能够保证一个topic的partition数量大于broker的数量，而且还需要把follower均匀的分布在所有的broker上，而不是只分布在一个 broker上。zookeeper 会对partition的leader follower等进行管理。Kafka分配Replica的算法如下： 将所有Broker（假设共n个Broker）和待分配的Partition排序将第i个Partition分配到第（i mod n）个Broker上将第i个Partition的第j个Replica分配到第（(i + j) mod n）个Broke leader election当Leader宕机了，怎样在Follower中选举出新的Leader？一种非常常用的Leader Election的方式是“Majority Vote”（“少数服从多数”），但Kafka并未采用这种方式。Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。 那么如何选取出leader：最简单最直观的方案是（谁写进去谁就是leader），所有Follower都在Zookeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（Zookeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。 Data Replication消息commit kafka在处理传播消息的时候，Producer会发布消息到某个partition上，先通知找到这个partition的leader replica，无论这个partition的 Replica factor是多少，Producer 先把消息发送给replica的leader，然后Leader在接受到消息后会写入到Log，这时候这个leader的其余follower都会去leader pull数据，这样可保证follower的replica的数据顺序和leader是一致的，follower在接受到消息之后写入到Log里面（同步），然后向leader发送ack确认，一旦Leader接收到了所有的ISR（与leader保持同步的Replica列表）中的follower的ack消息，这个消息就被认为是 commit了，然后leader增加HW并且向producer发送ack消息，表示消息已经发送完成。但是为了提高性能，每个follower在接受到消息之后就会直接返回给leader ack消息，而并非等数据写入到log里（异步），所以，可以认为对于已经commit的数据，只可以保证消息已经存在与所有的replica的内存中，但是不保证已经被持久化到磁盘中，所以进而也就不能保证完全发生异常的时候，该消息能够被consumer消费掉，如果异常发生，leader 宕机，而且内存数据消失，此时重新选举leader就会出现这样的情况，但是由于考虑大这样的情况实属少见，所以这种方式在性能和数据持久化上做了一个相对的平衡，consumer读取消息也是从 leader，并且只有已经commit之后的消息（offset小于HW）才会暴露给consumer。 消息确认kafka的存活条件包括两个条件： kafka必须维持着与zookeeper的session（这个通过zookeeper的heartbeat机制来实现） follower必须能够及时的将数据从leader复制过去 ，不能够“落后太多”。leader会跟踪与其保持着同步的replica列表简称ISR，（in-sync replica），如果一个follower宕机或是落后太多，leader就会把它从ISR中移除掉。这里指的落后太多是说 follower复制的消息落后的超过了预设值，（该值可在$KAFKA_HOME/config/server.properties中通过replica.lag.max.messages配置，其默认值是4000），或者follower超过一定时间（该值可在$KAFKA_HOME/config/server.properties中通过replica.lag.time.max.ms来配置，其默认值是10000）没有向leader发起fetch请求。 一条消息只有被ISR里的所有Follower都从Leader复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何Follower复制就宕机了，而造成数据丢失（Consumer无法消费这些数据）。而对于Producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。 0—表示不进行消息接收是否成功的确认；1—表示当Leader接收成功时确认；-1—表示Leader和Follower都接收成功时确认； 持久性kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性。且无论任何 OS 下,对文件系统本身的优化几乎没有可能。文件缓存/直接内存映射等是常用的手段。 因为 kafka 是对日志文件进行 append 操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数。 producer指定partitionproducer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何”路由层”.事实上,消息被路由到哪个partition上,有producer决定.比如可以采用”random””key-hash””轮询”等,如果一个topic中有多个partitions,那么在producer端实现”消息均衡分发”是必要的. 异步发送producer.type的默认值是sync，即同步的方式。这个参数指定了在后台线程中消息的发送方式是同步的还是异步的。如果设置成异步的模式，可以运行生产者以batch的形式push数据，这样会极大的提高broker的性能，但是这样会增加丢失数据的风险。 对于异步模式，还有4个配套的参数，如下： queue.buffering.max.ms 5000 启用异步模式时，producer缓存消息的时间。比如我们设置成1000时，它会缓存1s的数据再一次发送出去，这样可以极大的增加broker吞吐量，但也会造成时效性的降低。 queue.buffering.max.messages 10000 启用异步模式时，producer缓存队列里最大缓存的消息数量，如果超过这个值，producer就会阻塞或者丢掉消息。 queue.enqueue.timeout.ms -1 当达到上面参数时producer会阻塞等待的时间。如果设置为0，buffer队列满时producer不会阻塞，消息直接被丢掉；若设置为-1，producer会被阻塞，不会丢消息。 batch.num.messages 200 启用异步模式时，一个batch缓存的消息数量。达到这个数值时，producer才会发送消息。（每次批量发送的数量） 以batch的方式推送数据可以极大的提高处理效率，kafka producer可以将消息在内存中累计到一定数量后作为一个batch发送请求。batch的数量大小可以通过producer的参数（batch.num.messages）控制。通过增加batch的大小，可以减少网络请求和磁盘IO的次数，当然具体参数设置需要在效率和时效性方面做一个权衡。在比较新的版本中还有batch.size这个参数。 consumer consumer 采用pull的方式 从broker拉取数据。采用pull方式的优点有consumer端可以根据自己的消费能力适时的去fetch消息并处理,且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch. consumer端向broker发送fetch请求,并告知其获取消息的offset;此后consumer将会获得一定条数的消息;consumer端也可以重置offset来重新消费消息. kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支。对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,有consumer来控制;当consumer正常消费消息时,offset将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值，offset将会保存在zookeeper中。kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息有zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响。 at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后”未处理”的消息将不能被fetch到,这就是”at most once”. at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态. 消息的顺序性Kafka分布式的单位是partition，同一个partition用一个log文件（追加写、offset读），所以可以保证FIFO的顺序。但是在多个Partition时，不能保证Topic级别的数据有序性，除非创建Topic只指定1个partition，但这样做就磨灭kafka高吞吐量的优秀特性。 kafka为了提高Topic的并发吞吐能力，可以提高Topic的partition数，并通过设置partition的replica来保证数据高可靠。 Kafka 中发送1条消息的时候，可以指定(topic, partition, key) 3个参数，业务放使用producer插入数据时，可以控制同一Key发到同一Partition，从而保证消息有序性。一个partition的消息只能被一个consumer消费。 安装详情参见官网http://kafka.apache.org/安装会依赖java、zookeeper。 1234567891011121314151617181920212223brew install kafka//安装的配置文件位置/usr/local/etc/kafka/server.properties/usr/local/etc/kafka/zookeeper.properties//启动zookeeper -daemon 守护模式zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties &amp;//启动kafkakafka-server-start /usr/local/etc/kafka/server.properties &amp;//创建topic 创建单分区单副本的 topic test：kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test//查看创建的topickafka-topics --list --zookeeper localhost:2181//发送消息客户端bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test //消费消息kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning 参考文章：https://blog.csdn.net/gongzhiyao3739124/article/details/79688813]]></content>
  </entry>
  <entry>
    <title><![CDATA[AMQP和RabbitMQ]]></title>
    <url>%2F2018%2F08%2F08%2FRabbitMQ-AMQP%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[RabbitMQ 是一个由 Erlang 语言开发的 基于 AMQP 协议的开源MQ。高级消息队列协议（AMQP1）是一个异步消息传递所使用的应用层协议规范。作为线路层协议，而不是 API），AMQP 客户端能够无视消息的来源任意发送和接受信息。 RabbitMQ 最初起源于金融系统，用于在分布式系统中消息传递，在易用性、扩展性、高可用性等方面表现不俗。 MQ模型所有MQ都包含3个基本对象生产者（producer/publisher），队列（queue），消费者（consumer）。 消费者（consumer）订阅某个队列（queue）。生产者（producer）创建消息，然后发布到队列（queue）中，最后消息通过pull或者push的方式发送到监听的消费者。如下图： AMQP模型https://img-blog.csdn.net/20170918215545604?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjc1ODA4OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast 首先看下上面的组成元素： Message：消息体，包含header和body，body是不透明的，header包含很多可选的消息属性，包括routing-key（路由键）、priority（优先级）、delivery-mode（是否需要持久性存储）等 Broker：可以理解为物理服务器实体，它在 TCP/IP 等端口监听 AMQ 消息。 一个Broker可以划分为一到多个Virtual Host（虚拟主机） Message Queue：消息队列。可存储在内存或磁盘，每个队列独立互不影响，可以设置私有或共享、是否持久化等多种属性。 Producer和Consumer构成AMQP的客户端，Broker构成AMQP的服务端 Exchange: 交换器。Exchange的设计引入，主要为了解决将producer的消息按照不用策略分发到不同queue的问题。Exchange可以绑定多个Queue也可以同时绑定其他Exchange。消息通过Exchange时，会按照Exchange中设置的Routing（路由）规则，将消息发送到符合的Queue或者Exchange中 Binding：exchange和queue的绑定的路由信息 Channel：client建议的connection是基于tcp,对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。一个Connection上允许存在多个Channel，只有Channel中能够发送/接受消息。 Exchange 类型Exchange必须至少已经和某个Queue或者另外的Exchange形成了绑定关系，并设置好了到这些Queue和Excahnge的Routing（路由规则），才可以处理消息。 Exchange根据消息分发策略的不同分为四种类型：direct、fanout、topic、headers。 其中headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 和 direct 完全一致，但性能差很多，目前几乎用不到了，不多作介绍了。 direct: 校验key，只有当消息的routing key和队列的binding key一致时，才将消息转发到queue上。属于单一匹配。 topic：校验key，queue需要绑定到一个模式上，只有消息的routing key跟模式匹配时才会转发。 fanout: 不校验key，将消息分发到所有跟Exchange绑定的队列上，类似广播。fanout 类型转发消息是最快的，也是最常用的。 Queue属性 持久性：如果启用，队列将会在协商器重启前都有效。 自动删除：如果启用，那么队列将会在所有的消费者停止使用之后自动删除掉自身。 惰性：如果没有声明队列，那么在执行到使用的时候会导致异常，并不会主动声明。 私有性：如果启用，队列只能被声明它的消费者使用。 RabbitMQ的队列是可以设置为临时自行删除的，但是实际业务应用中，为了保证数据的安全性，我们通常都会将其设为持久化保存的。 如果Exchange交换机没有找到任何匹配Routing Key的Queue，那么这条AMQP消息会被丢弃。只有Queue有保存消息的功能，但是Exchange并不负责保存消息。 RabbitMQ模型 总结一下发送消息的过程就是：消息生产者（Producer）首先要声明一个它想要的交换器（Exchange），然后使用绑定器（Binding）将交换器与其他交换器或者队列（没有必须先声明）绑定，然后消息就可以通过Producer-&gt;Exchange-&gt;Queque。而消费消息，只需要消费者（Consumer）订阅一个队列，就能够从队列中获取消息，然后成功使用过后将其从队列中删除。 消息投递的保障机制消费者会显式或者隐式地通知消息的使用完毕。当隐式地通知的时候，消息被认为在投递之后便被消耗掉。否则客户端需要显式地发送一个验证信息。只有这个验证信息收到之后，消息才会被认为已经收到并且从队列中删除。如果没有收到，那么协商器会在通道20关闭之前尝试着重新投递消息。 消息生产者可以选择是否在消息被发送到交换器并且还未投递到队列（没有绑定器存在）和 / 或没有消费者能够立即处理的时候得到通知。通过设置消息的 mandatory 和 / 或 immediate 属性为真，这些投递保障机制的能力得到了强化。 此外，一个生产者可以设置消息的 persistent 属性为真。这样一来，协商器将会尝试将这些消息存储在一个稳定的位置，直到协商器崩溃。当然，这些消息肯定不会被投递到非持久的队列中。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>AMQP</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[布隆过滤器（Bloom Filter)介绍]]></title>
    <url>%2F2018%2F05%2F08%2FBloomFilter%2F</url>
    <content type="text"><![CDATA[首先看下面几个场景： 字处理软件中，需要检查一个英语单词是否拼写正确 在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上 网页爬虫对URL的去重，避免爬取相同的URL地址 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信） 缓存击穿，将已存在的缓存放到布隆过滤器中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉。 以上场景归纳为一个问题就是：如何在一个很大数据集合中迅速查询一个元素？ 有人会说，我们可以直接把数据放在redis缓存或者存在数据库，查询的时候直接匹配就不就ok？当数据量比较小，我们内存够大的时候的确可以这样处理，甚至可以直接用HashSet、HashMap解决，但是如果我们数据量很大，几千万或者几亿，这种情况下又如何处理呢？布隆过滤器就应运而生。 基本概念布隆过滤器实际上是一个很长的二进制向量（位数组）和一系列随机映射函数（哈希），作用就在于能跟迅速判断一个元素是否在一个集合中，且查询效率很高（1-N，最优能近于1）。 哈希函数首先简单介绍下哈希函数：将任意大小的数据转换成特定大小的数据的函数，转换后的数据称为哈希值或哈希编码。比如我们常用的md5。下面一副示意图： 原始数据与哈希编码的映射是近乎一对一的（非常非常低的几率下两个不同key的hash值是可能重复的）。哈希函数是实现哈希表和布隆过滤器的基础。 布隆过滤器原理：初始状态下是一个m位的全为0的bit数组，以及k个hash函数，如下图所示 假定我们要维护的集合为{N1, N2}，首先输入N1，经过hash函数f1(N1)%m得到2，f2(N1)%m得到5，那么就将bit数组的2，5位置改为1，如下图所示： 同理计算N2： 此时，如果我们要查询一个元素N3，判断N3是否在集合{N1, N2}中，我们只需要进行f1(N3)%m，f2(N3)%m的计算：如果f1(N3)%m，f2(N3)%m对应下标的值有一个为0，那就说明元素不在集合内，反之如果两个值都为1，则说明元素在集合内。但实际上存在元素不在集合中却对应都为1的情况，这就是误判率的存在。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。 通常我们需要根据实际业务来计算误判率，确定m/n和k的值（m代表bit数组长度，n代表集合元素数，k代表hash函数个数），具体可以参考这篇文章。 由上我们可以看出布隆过滤器的优点就是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难（一般情况下是不能删除的）。 php和redis实现bloom filter方法第一步，获取几个hash函数，比如BKDRHash，JSHash，RSHash等等。这些hash函数我们直接获取就可以了。12345678910111213141516171819202122/**函数集合类*/class HashSet &#123; const JSHASH = &apos;JSHash&apos;; const BKDRHASH = &apos;BKDRHash&apos;; const RSHASH = &apos;RSHash&apos;; const PJWHASH = &apos;PJWHash&apos;; const ELFHash = &apos;ELFHash&apos;; const BKDRHash = &apos;BKDRHash&apos;; const SDBMHash = &apos;SDBMHash&apos;; const DJBHash = &apos;DJBHash&apos;; const DEKHash = &apos;DEKHash&apos;; const FNVHash = &apos;FNVHash&apos;; //函数具体实现不详述了 public static function JSHash($string) &#123;&#125; public static function BKDRHash($string) &#123;&#125; public static function RSHash($string) &#123;&#125; public static function BKDRHash($string) &#123;&#125; public static function SDBMHash($string) &#123;&#125; ...&#125; 第二步，使用redis的setBit和getBit操作来实现过滤器。当然我们也可以用php作位运算，但是比较麻烦这里不赘述了。值得注意的是setBit和getBit必须2.2以上版本的redis才能支持。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/**使用redis实现的布隆过滤器*/abstract class BloomFilterBase &#123; //bit数组 protected $bit_array_name; protected $bit_array_length; //hash函数集合 protected $hash_set; protected $redis_obj; public function __construct() &#123; if (!$this-&gt;hash_set) &#123; $this-&gt;hash_set = HashSet::$hash_set; &#125; $this-&gt;redis_obj = new Redis; &#125; /**定义bitArray */ public function setBitArray($name, $lengh) &#123; $this-&gt;bit_array_name = $name; $this-&gt;bit_array_lengh = $length; &#125; /**添加元素到集合 */ public function add ($string) &#123; if (!$this-&gt;bit_array_name || !$this-&gt;bit_array_length) &#123; throw new Exception(&quot;需要预定义bitArray&quot;, 1); &#125; foreach ($this-&gt;hash_set as $function) &#123; $hash = HashSet::$function($string) % $this-&gt;bit_array_length; $this-&gt;redis_obj-&gt;setBit($this-&gt;bit_array_name, $hash, 1); &#125; &#125; /**判断是否存在 */ public function isExists($string) &#123; if (!$this-&gt;bit_array_name || !$this-&gt;bit_array_length) &#123; throw new Exception(&quot;需要预定义bitArray&quot;, 1); &#125; foreach ($this-&gt;hash_set as $function) &#123; $hash = HashSet::$function($string) % $this-&gt;bit_array_length; $res = $this-&gt;redis_obj-&gt;getBit($this-&gt;bit_array_name, $hash); if ($res == 0) &#123; return false; &#125; &#125; return true; &#125;&#125; 第三步，上面定义的是一个抽象类，可以根据具体的业务来使用。123456789101112131415161718/** * 重复内容过滤器 * 该布隆过滤器总位数为2^32位, 判断条数为2^30条. hash函数最优为3个.(能够容忍最多的hash函数个数) * 使用的三个hash函数为 * BKDR, SDBM, JSHash * * 注意, 在存储的数据量到2^30条时候, 误判率会急剧增加, 因此需要定时判断过滤器中的位为1的的数量是否超过50%, 超过则需要清空. */class FilteRepeatedComments extends BloomFilterBase&#123; protected $bit_array_name = &apos;repeated_comments_bloom_filter&apos;; protected $bit_array_length = 0xFFFFFFFF; protected $hash_set = array( HashSet::JSHASH, HashSet::BKDRHASH, HashSet::RSHASH, );&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[消息队列MQ]]></title>
    <url>%2F2018%2F03%2F08%2FMQ%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[介绍MQ算是我们日常开发过程中使用最多最频繁之一的中间件了。这里对MQ的特点和使用场景做下简单介绍总结。 什么是MQ消息队列（Message Queue）简称MQ，是一种跨进程的通信机制，常用于上下游“逻辑解耦+物理解耦”的消息通信服务。上下游的关系可以理解为发布-订阅模式。 MQ的优势和不足优势： 1）同步调用改异步，提高性能 2）解决业务的相互依赖，解耦 3）可以控制下游服务的执行效率，达到缓冲流量、削峰填谷的目的 MQ的不足： 1）上游无法知道下游的执行结果。这一点是最重要的，因此很多需要实时调用返回执行结果的业务场景，是无法使用MQ的。 2）系统更复杂，多了一个MQ组件 3）消息传递路径更长，延时会增加 4）消息可靠性和重复性互为矛盾，消息不丢不重难以同时保证 MQ的应用场景MQ主要应用于异步解耦、削峰填谷等，在一些上游服务不需要实时获取下游服务的执行结果的场景中频繁使用。 应用一：高并发下的缓冲流量、削峰填谷比如秒杀抢购等高并发写库场景，如果在接口程序中实时写库操作，可能会对数据库造成极大压力而导致崩溃，优化方案之一，就是对提交的数据校验成功后将其推到MQ，再调取下游写库服务，以此来控制写库频率。值得注意的是，这套流程还需要注意写库服务失败后处理，比如写库失败直接扔回queue还是触发另外的机制等。 应用二：上游不关心下游执行结果，异步调用，提高性能这个也是在我们接口开发中使用比较多的场景。因为接口的性能都会要求比较高，业务很复杂的情况下，很多不需要在实时返回接口的业务程序，一般都会拆离出去，通过MQ异步调用。 单线程同步调用时：上游-&gt;下游1-&gt;下游2-&gt;下游3 通过MQ异步调用： 【场景1：发帖】比如58同城招聘用户发布帖子后，招聘业务要奖励58豆，房产用户发布帖子后，房产业务要送2个置顶，二手用户发布帖子后，二手业务要修改用户统计数据。 应用三：解决任务依赖，解耦举个栗子，互联网公司经常在凌晨进行一些数据统计任务，这些任务之间有一定的依赖关系，比如： 1）task3需要使用task2的输出作为输入 2）task2需要使用task1的输出作为输入 这样的话，tast1, task2, task3之间就有任务依赖关系，必须task1先执行，再task2执行，载task3执行。 MQ解耦： 【场景2：下订单】通常电商的订单系统跟仓库系统等都是分离的，用户下订单之后，无需关注后续仓库物流打包等操作，通过MQ解耦 我司的push系统也是采用这种方式来实现的。值得注意的是这套方案，会导致系统格外复杂，代码分散，维护的成本非常高。 应用四：上游关注执行结果，但执行时间很长 有时候上游需要关注执行结果，但执行结果时间很长（典型的是调用离线处理，或者跨公网调用），也经常使用回调网关+MQ来解耦。 举个栗子，微信支付，跨公网调用微信的接口，执行时间会比较长，但调用方又非常关注执行结果，此时一般怎么玩呢？ 一般采用“回调网关+MQ”方案来解耦： 1）调用方直接跨公网调用微信接口 2）微信返回调用成功，此时并不代表返回成功 3）微信执行完成后，回调统一网关 4）网关将返回结果通知MQ 5）请求方收到结果通知 这里需要注意的是，不应该由回调网关来调用上游来通知结果，如果是这样的话，每次新增调用方，回调网关都需要修改代码，仍然会反向依赖，使用回调网关+MQ的方案，新增任何对微信支付的调用，都不需要修改代码啦。 总结：MQ是异步解耦，削峰填谷的利器。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ（二）：安装 和 PHP Client]]></title>
    <url>%2F2018%2F03%2F04%2FRabbitMQ-PHPClient%2F</url>
    <content type="text"><![CDATA[安装根据操作系统不同官网提供了相应的安装说明：Windows、Debian / Ubuntu、RPM-based Linux、Mac Mac 用户推荐使用 HomeBrew 来安装：1brew install rabbitmq 安装过程中会自动其所依赖的 Erlang 。 启动RabbitMQ server scripts 和 CLI tools被安装在/usr/local/sbin 添加环境变量:1export PATH=$PATH:/usr/local/sbin 启动： 1rabbitmq-server 如下图则表示正常启动，completed with 6 plugins 表示启动的时候默认加载了6个插件：日志：/var/log/rabbitmq目录下找到名为rabbit@[hostname].log日志文件 常用命令：首先介绍两个概念，Erlang的节点和应用程序：节点可以理解为Erlang 的虚拟机，一个节点可以同时运行多个应用程序。节点之间可以进行本地通信（不管他们是不是运行在同一台服务器之上）。比如一个运行在节点A上的应用程序可以调用节点B上应用程序的方法，就好像调用本地函数一样。如果应用程序由于某些原因奔溃，Erlang 节点会自动尝试重启应用程序。 12345678910111213141516171819202122232425262728293031//守护进程方式后台运行rabbitmq-server -detached//查询服务器状态rabbitmqctl status//关闭 RabbitMQ 节点，默认 node 名称是 rabbit@server rabbitmqctl stop//关闭指定noderabbitmqctl -n rabbit@server.example.com stop //关闭 RabbitMQ 应用程序，保持Erlang节点运行（这个命令在集群模式中将会很有用）rabbitmqctl stop_app//启动 RabbitMQ 应用程序rabbitmqctl start_app//重置 RabbitMQ 节点（该命令会清除所有的队列）：rabbitmqctl reset//查看已声明的队列rabbitmqctl list_queues//查看交换器rabbitmqctl list_exchanges//该命令还可以附加参数，比如列出交换器的名称、类型、是否持久化、是否自动删除：rabbitmqctl list_exchanges name type durable auto_delete//查看绑定rabbitmqctl list_bindings 更多命令参照官网 PHP Client详细文档参照官网 下载安装php-amqplib扩展，建议使用Composer安装 12345&#123; &quot;require&quot;: &#123; &quot;php-amqplib/php-amqplib&quot;: &quot;&gt;=2.6.1&quot; &#125;&#125; send.php 1234567891011121314151617181920&lt;?phprequire_once __DIR__ . &apos;/vendor/autoload.php&apos;;use PhpAmqpLib\Connection\AMQPStreamConnection;use PhpAmqpLib\Message\AMQPMessage;//create a connection to the server$connection = new AMQPStreamConnection(&apos;localhost&apos;, 5672, &apos;guest&apos;, &apos;guest&apos;);$channel = $connection-&gt;channel();//declare a queue for us to send to$channel-&gt;queue_declare(&apos;hello&apos;, false, false, false, false);//publish a message to the queue$msg = new AMQPMessage(&apos;Hello World!&apos;);$channel-&gt;basic_publish($msg, &apos;&apos;, &apos;hello&apos;);echo &quot; [x] Sent &apos;Hello World!&apos;\n&quot;;//close the channel and the connection;$channel-&gt;close();$connection-&gt;close(); 发送消息前，必须先声明一个队列。值得注意的是，这里的队列声明是幂等的，即只有才队列不存在的情况才会去创建。消息的主体是一个二进制数组(byte array)，因此我们可以自己随意选择编码方式，而不影响传输。 receive.php1234567891011121314151617181920require_once __DIR__ . &apos;/vendor/autoload.php&apos;;use PhpAmqpLib\Connection\AMQPStreamConnection;$connection = new AMQPStreamConnection(&apos;localhost&apos;, 5672, &apos;guest&apos;, &apos;guest&apos;);$channel = $connection-&gt;channel();//Note that we declare the queue here, as well. Because we might start the consumer before the publisher, we want to make sure the queue exists before we try to consume messages from it.$channel-&gt;queue_declare(&apos;hello&apos;, false, false, false, false);echo &quot; [*] Waiting for messages. To exit press CTRL+C\n&quot;;$callback = function ($msg) &#123; echo &apos; [x] Received &apos;, $msg-&gt;body, &quot;\n&quot;;&#125;;$channel-&gt;basic_consume(&apos;hello&apos;, &apos;&apos;, false, true, false, false, $callback);while (count($channel-&gt;callbacks)) &#123; $channel-&gt;wait();&#125; 注意：这里接受消息我们也要先声明队列，因为实际应用中我们可能需要producer发送前先启动worker，所以我们要确保在我们消费消息之前队列存在。 consumer获取消息的方式是MQ按照push的方式分发给worker的，如果我们启动多个worker，那么我们就会发现每次我们推给mq的消息会被依次分发给各个worker消费。 4.消息确认（Message Acknowledgement）rabbitmq的消息确认机制默认是被关闭的。如果我们在worker处理消息过程中杀死worker，那么worker重启之后，这条任务就会丢失。如果要确保任务不会丢失，就要使用以下代码:1234567$callback = function ($msg) &#123; echo &apos; [x] Received &apos;, $msg-&gt;body, &quot;\n&quot;; //ack回调 $msg-&gt;delivery_info[&apos;channel&apos;]-&gt;basic_ack($msg-&gt;delivery_info[&apos;delivery_tag&apos;]);&#125;;$channel-&gt;basic_consume(&apos;task_queue&apos;, &apos;&apos;, false, false, false, false, $callback); 增加以上ack机制后，mq只有在收到确认之后才会将任务从队列中删除。 消息持久化（Message durability）上面介绍的是如何在consumer崩溃的时候，task不丢失。但是当rabbitmq崩溃的时候queue和task仍然会丢失，很明显这是我们不能接受的，下面的代码就是如何让我们的queue和task持久化：1234567//声明持久化的队列$channel-&gt;queue_declare(&apos;task_queue&apos;, false, true, false, false); //第三个参数为true//消息持久化存储在队列中$msg = new AMQPMessage( $data, array(&apos;delivery_mode&apos; =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT));]]></content>
  </entry>
  <entry>
    <title><![CDATA[浅谈缓存穿透、缓存雪崩和缓存击穿]]></title>
    <url>%2F2018%2F01%2F06%2F%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%2F</url>
    <content type="text"><![CDATA[缓存系统是我们平时开发经常使用到的，也是在高并发场景下减少或防止流量对DB等底层系统冲击的最有效手段之一。下面就简单谈谈缓存系统经常提及的三个问题以及解决方案。 缓存穿透首先回忆下通常情况我们设置的缓存机制，如下图所示：这套机制，由于出于容错考虑，从存储层查不到数据则不写入缓存，这就导致每次请求不存在的数据时都要到存储层去查询。如果有黑客可以利用不存在的key，频繁请求我们的服务器，这些请求就会穿透缓存，直接打到DB上，对DB造成巨大压力甚至挂掉。这就是缓存穿透。 解决方案有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器（bloom filter）。 布隆过滤器是将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 另外一个更为简单粗暴的方法，如果一个查询结果空（不管是数 据不存在，还是查询异常），我们仍然把这个空结果进行缓存，但它的过期时间会很短，几分钟即可。 缓存雪崩缓存雪崩是指在如果我们几乎在同一时间设置的缓存（比如缓存预热），并且设置了相同的过期时间，这就会导致缓存会在某一时刻同时失效，这个时间所有请求会全部转发到DB，DB瞬时压力过重雪崩。 解决方案大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。另一个简单的方案就是我们可以在原有的失效时间基础上增加一个随机值，让缓存的失效时间错开，就可以有效的避免缓存雪崩。 缓存击穿缓存击穿跟缓存雪崩类似，区别就是缓存雪崩是群体失效，缓存击穿是单体失效，比如一个非常热点的数据。比较典型的场景就是新浪微博的热点事件，比如鹿晗和关晓彤事件，因为超高并发的访问，如果这个时间点缓存过期，在系统从后端DB加载数据到缓存这个过程中，这段时间超大并发的请求会同时打到DB上，很有可能瞬间把DB压垮。相关推荐阅读：双11万亿流量下的分布式缓存 解决方案1.使用互斥锁（mutex lock)：简单地来说，就是在缓存失效的时候，不是直接请求DB，而是先加分布式锁（比如redis的setNx），如果加锁成功，再进行load db的操作并回设缓存；如果加锁失败，说明已经有别的进程在加锁重设缓存，我们只需要等待重试或者直接返回客户端失败让用户手动重试。 这是比较简单，也是很常用的一种解决方式。值得注意的是，我们加锁的时候一定要设置过期时间（如redis的expire），否则会有死锁的风险。 2. 提前更新缓存：上面一种方案，因为用户是有感知的，如果不想影响用户体验，可以进一步优化为对缓存加标，并记录它的过期时间，当我们读取缓存的时候，先判断它是否快到过期时间，如果是则在返回缓存数据的同时，后台异步请求DB重设缓存，更新它的过期时间。而如果我们获取缓存是缓存已经过期，则还需要我们按照上一个方案处理。 3. “永不失效”：在上面情况下，我们进一步思考，如果我们设置缓存的过期时间非常长（比如3天），同时我们对缓存加标记录设置缓存的时间，每次我们读取缓存的时候，拿到设置缓存的时间跟现在的时间做比对，如果相差时间超过10分钟，我们在后台异步更新缓存。这样对于热点数据而言，就相当于缓存“永不失效”了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL规范]]></title>
    <url>%2F2017%2F11%2F05%2FMySQL%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[一、基础规范表存储引擎必须使用InnoDB解读：线上 DB 统一使用 InnoDB 存储引擎，线下统计类从库也可用Ｍyisam 引擎 表字符集默认使用utf8mb4，而不是utf8解读：（1）通用，无乱码风险，汉字3字节，英文1字节（2）utf8mb4是utf8的超集，emoji表情以及部分不常见汉字在utf8下会表现为乱码 禁止使用存储过程，视图，触发器，Event解读：（1）对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层（2）调试，排错，迁移都比较困难，扩展性较差（3）高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能” 禁止在数据库中存储大文件，例如照片，可以将大文件存储在对象存储系统，数据库中存储路径解读：大文件和照片存储在文件系统，数据库里存URI所有表、所有字段都需要加注释，推荐采用英文标点，避免出现乱码。状态类字段需説明每个状态的意义： 0:fail 1:pass 2:pending单表数据行数建议控制在 2000W－3000W 以内，单表数据量控制在5G以下（大于这个数请前期设计的时候分表）禁止在线上环境做数据库压力测试测试，开发，线上数据库环境必须隔离 二、命名规范库名、表名使用大驼峰（类似UserGroupRecord），列名必须用小写，采用下划线分隔库名、表名、字段名禁止使用 MySQL 保留字库名，表名，列名必须见名知义，长度不要超过32字符解读：tmp，wushan谁TM知道这些库是干嘛的禁止使用拼音，除了没有英文名的（比如：哈药 hayao），其它都用英文禁止表名后面跟日期：tablename2015(建表之前与业务沟通，线上建表必须与业务结合起来，避免按自己的意思去单独建表)临时库、表名必须以 tmp 为前缀，并以日期为后缀。例如tmp_lama_20150427。（临时表用完后必须删除）库备份必须以bak为前缀，以日期为后缀从库必须以-s为后缀备库必须以-ss为后缀只允许使用内网域名，而不是ip连接数据库线上环境、开发环境、测试环境数据库内网域名遵循命名规范业务名称：xxx线上环境：dj.xxx.db开发环境：dj.xxx.rdb测试环境：dj.xxx.tdb从库在名称后加-s标识，备库在名称后加-ss标识线上从库：dj.xxx-s.db线上备库：dj.xxx-sss.db 三、表设计规范表必须有主键，推荐使用UNSIGNED整数为主键解读：1）主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用2）主键要选择较短的数据类型，Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率3）删除无主键的表，如果是row模式的主从架构，从库会挂住单实例表个数必须控制在500个以内（一个数据库最多500张表）单表分表个数必须控制在1024个以内禁止使用外键，如果要保证完整性，应由应用程式实现解读：外键使得表之间相互耦合，影响update/delete等SQL性能，十分影响sql性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈，大数据高并发业务场景数据库使用以性能优先 建议将大字段，访问频度低的字段拆分到单独的表中存储，分离冷热数据解读：具体参加《如何实施数据库垂直拆分》 若需分表，表名后缀使用十进制数，数字建议从0开始(table_1，table_2，table_3)按日期时间分表需符合 YYYY[MM][DD][HH]格式。（例如 2013071601。年份必须用 4 位数字表示。例如按日散表 user_20110209、按月散表 user_201102） 四、列设计规范根据业务区分使用tinyint/smallint/int/bigint，分别会占用1/2/4/8字节INT 类型固定占 4 字节存储，例如 INT(4)仅代表显示字符宽度为 4 位，不代表存储长度根据业务区分使用char/varchar解读：（1）字段长度固定，或者长度近似的业务场景，适合使用char，能够减少碎片，查询性能高（2）字段长度相差较大，或者更新较少的业务场景，适合使用varchar，能够减少空间 使用尽可能小的 VARCHAR 字段。VARCHAR(N)中的 N 表示字符数而非字节数根据业务区分使用datetime/timestamp解读：前者占用5个字节，后者占用4个字节，存储年使用YEAR，存储日期使用DATE，存储时间使用datetime 必须把字段定义为NOT NULL并设默认值解读：（1）NULL的列使用索引，索引统计，值都更加复杂，MySQL更难优化（2）NULL这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多（3）NULL需要更多的存储空间（3）NULL只能采用IS NULL或者IS NOT NULL，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’shenjian’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录 建议使用 UNSIGNED 存储非负数值使用 VARBINARY 存储大小写敏感的变长字符串或二进制内容使用INT UNSIGNED存储IPv4，不要用char(15)使用varchar(20)存储手机号，不要使用整数解读：（1）牵扯到国家代号，可能出现+/-/()等字符，例如+86（2）手机号不会用来做数学运算（3）varchar可以模糊查询，例如like ‘138%’ 使用TINYINT来代替ENUM解读：ENUM增加新值要进行DDL操作。用 DECIMAL 代替 FLOAT 和 DOUBLE 存储精确浮点数，例如支付相关数据尽可能不使用 TEXT、BLOB 类型解读：会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能单表字段个数控制在 30 以下 五、索引规范唯一索引使用uniq_[字段名]来命名非唯一索引使用idx_[字段名]来命名索引名必须全部使用小写表必须有主键，推荐使用 UNSIGNED 自增列作为主键单张表索引数量建议控制在5个以内解读：（1）互联网高并发业务，太多索引会影响写性能（2）生成执行计划时，如果索引太多，会降低性能，并可能导致MySQL选择不到最优索引（3）异常复杂的查询需求，可以选择ES等更为适合的方式存储 组合索引字段数不建议超过5个解读：如果5个字段还不能极大缩小row范围，八成是设计有问题 不建议在频繁更新的字段上建立索引解读：更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能 不在低基数，区分度不高的列上建立索引。例如“性别”，不能有效过滤数据，性能与全表扫描非必要不要进行JOIN查询，如果要进行JOIN查询，被JOIN的字段必须类型相同，并建立索引解读：踩过因为JOIN字段类型不一致，而导致全表扫描的坑么？ 理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b), (a,b,c)禁止冗余索引禁止重复索引禁止使用外键 六、SQL规范禁止使用select ，只获取必要字段解读：（1）select 会增加cpu/io/内存/带宽的消耗（2）指定字段能有效利用索引覆盖（3）指定字段查询，在表结构变更时，能保证对应用程序无影响 insert必须指定字段，禁止使用insert into T values()解读：指定字段插入，在表结构变更时，能保证对应用程序无影响 禁止隐式转换。数值类型禁止加引号；字符串类型必须加引号解读：隐式类型转换会使索引失效，导致全表扫描 禁止在where条件列使用函数或者表达式解读：导致不能命中索引，全表扫描 禁止负向查询NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等以及%开头的模糊查询解读：导致不能命中索引，全表扫描 禁止大表JOIN和子查询。必要时推荐用 JOIN 代替子查询解读：会产生临时表，消耗较多内存与CPU，极大影响数据库性能 同一个字段上的OR必须改写问IN，IN的值必须少于50个解读：旧版本Mysql的OR查询是不能命中索引的，即使能命中索引，为何要让数据库耗费更多的CPU帮助实施查询优化呢？ 应用程序必须捕获SQL异常使用 EXPLAIN 判断 SQL 语句是否合理使用索引force–index（对于单独条件如果走不了索引，强要强制指定索引）拆分复杂 SQL 为多个小 SQL，避免大事务减少与数据库交互次数，尽量采用批量 SQL 语句获取大量数据时，建议分批次获取数据，每次获取数据少于 2000 条，结果集应小于 1MMyisam 引擎统计行数用 COUNT(*)。InnoDB 引擎统计行数用 COUNT(主键 id）建议使用合理的分页方式以提高分页效率解读：方便定位线上问题 七、行为规范禁止使用应用程序配置文件内的帐号手工访问线上数据库禁止非DBA对线上数据库进行写操作，修改线上数据需要提交工单，由DBA执行，提交的SQL语句必须经过测试分配非DBA以只读帐号，必须通过VPN+跳板机访问授权的从库开发、测试、线上环境隔离禁止有 super 权限、DDL、DCL 权限的应用程序账号存在表结构变更必须通知 DBA 进行审核，大表 DDL 操作提前一天发送需求，避免大于 5000 万行记录的表进行 DDL 操作，除开特殊情况不要在 MySQL 数据库中存放业务逻辑master 上面，除了业务需要实时查询的 select，其它的 select 必须放在slave 上面统计相关，后台查询相关的 select，禁止放在线上从库上面。这种类型的统一放在线下的统计从库上面 参考文章：https://cloud.tencent.com/developer/article/1004367https://mp.weixin.qq.com/s/YfCORbcCX1hymXBCrZbAZghttps://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959906&amp;idx=1&amp;sn=2cbdc66cfb5b53cf4327a1e0d18d9b4a&amp;chksm=bd2d07be8a5a8ea86dc3c04eced3f411ee5ec207f73d317245e1fefea1628feb037ad71531bc&amp;scene=21#wechat_redirecthttps://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651959910&amp;idx=1&amp;sn=6b6853b70dbbe6d689a12a4a60b84d8b&amp;chksm=bd2d07ba8a5a8eac6783bac951dba345d865d875538755fe665a5daaf142efe670e2c02b7c71&amp;scene=21#wechat_redirect]]></content>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 安装配置]]></title>
    <url>%2F2017%2F08%2F14%2FNginx%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E7%AF%87%2F</url>
    <content type="text"><![CDATA[nginx.conf 配置结构1234567891011121314151617181920212223242526272829... #全局块events &#123; #events块...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 1、main全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。3、http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。5、location块：配置请求的路由，以及各种页面的处理情况。 不同模块指令关系：server继承main；location继承server；upstream既不会继承指令也不会被继承，它有自己的特殊指令，不需要在其他地方的应用 nginx.conf 基本配置模板每个指令必须有分号结束123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188########### 每个指令必须有分号结束。##################配置用户或者组，默认为nobody nobody。#user administrator administrators; #允许生成的进程数，默认为1#worker_processes 2; #指定nginx进程运行文件存放地址#pid /nginx/pid/nginx.pid; #制定错误日志路径，级别。这个设置可以放入全局块，http块，server块，级别依次为：debug|info|notice|warn|error|crit|alert|emergerror_log log/error.log debug; #工作模式及连接数上限events &#123;#设置网路连接序列化，防止惊群现象发生，默认为on accept_mutex on; #设置一个进程是否同时接受多个网络连接，默认为off multi_accept on; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport#use epoll; #单个work进程允许的最大连接数，默认为512 worker_connections 1024; &#125;#http服务器http &#123;#文件扩展名与文件类型映射表。设定mime类型(邮件支持类型),类型由mime.types文件定义#include /usr/local/etc/nginx/conf/mime.types; include mime.types; #默认文件类型，默认为text/plain default_type application/octet-stream; #取消服务访问日志#access_log off; #自定义日志格式 log_format myFormat &apos;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&apos;; #设置访问日志路径和格式。&quot;log/&quot;该路径为nginx日志的相对路径，mac下是/usr/local/var/log/。combined为日志格式的默认值 access_log log/access.log myFormat; rewrite_log on;#允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。（sendfile系统调用不需要将数据拷贝或者映射到应用程序地址空间中去） sendfile on; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 sendfile_max_chunk 100k; #连接超时时间，默认为75s，可以在http，server，location块。 keepalive_timeout 65; #gzip压缩开关#gzip on; tcp_nodelay on;#设定实际的服务器列表 upstream mysvr1 &#123; server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备(其它所有的非backup机器down或者忙的时候，请求backup机器)) &#125; upstream mysvr2 &#123;#weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.1.11:80 weight=5; server 192.168.1.12:80 weight=1; server 192.168.1.13:80 weight=6; &#125; upstream https-svr &#123;#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题 ip_hash; server 192.168.1.11:90; server 192.168.1.12:90; &#125;#error_page 404 https://www.baidu.com; #错误页#HTTP服务器# 静态资源一般放在nginx所在主机 server &#123; listen 80; #监听HTTP端口 server_name 127.0.0.1; #监听地址 keepalive_requests 120; #单连接请求上限次数 set $doc_root_dir &quot;/Users/doing/IdeaProjects/edu-front-2.0&quot;; #设置server里全局变量 #index index.html; #定义首页索引文件的名称 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 root $doc_root_dir; #静态资源根目录 proxy_pass http://mysvr1; #请求转向“mysvr1”定义的服务器列表 #deny 127.0.0.1; #拒绝的ip #allow 172.18.5.54; #允许的ip &#125; &#125;#http server &#123; listen 80; server_name www.helloworld.com; #监听基于域名的虚拟主机。可有多个，可以使用正则表达式和通配符 charset utf-8; #编码格式 set $static_root_dir &quot;/Users/doing/static&quot;; location /app1 &#123; #反向代理的路径（和upstream绑定），location后面设置映射的路径 proxy_pass http://zp_server1; &#125; location /app2 &#123; proxy_pass http://zp_server2; &#125; location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #静态文件，nginx自己处理 root $static_root_dir; expires 30d; #静态资源过时间30天 &#125; location ~ /\.ht &#123; #禁止访问 .htxxx 文件 deny all; &#125; location = /do_not_delete.html &#123; #直接简单粗暴的返回状态码及内容文本 return 200 &quot;hello.&quot;; &#125;# 指定某些路径使用https访问(使用正则表达式匹配路径+重写uri路径) location ~* /http* &#123; #路径匹配规则：如localhost/http、localhost/httpsss等等#rewrite只能对域名后边的除去传递的参数外的字符串起作用，例如www.c.com/proxy/html/api/msg?method=1&amp;para=2只能对/proxy/html/api/msg重写。#rewrite 规则 定向路径 重写类型;#rewrite后面的参数是一个简单的正则。$1代表正则中的第一个()。#$host是nginx内置全局变量，代表请求的主机名#重写规则permanent表示返回301永久重定向 rewrite ^/(.*)$ https://$host/$1 permanent; &#125;#错误处理页面（可选择性配置）#error_page 404 /404.html;#error_page 500 502 503 504 /50x.html;#以下是一些反向代理的配置(可选择性配置)#proxy_redirect off;#proxy_set_header Host $host; #proxy_set_header用于设置发送到后端服务器的request的请求头#proxy_set_header X-Real-IP $remote_addr;#proxy_set_header X-Forwarded-For $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP#proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)#proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)#proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)#proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小#proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置#proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）#proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传#client_max_body_size 10m; #允许客户端请求的最大单文件字节数#client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 &#125;#https#(1)HTTPS的固定端口号是443，不同于HTTP的80端口；#(2)SSL标准需要引入安全证书，所以在 nginx.conf 中你需要指定证书和它对应的 key server &#123; listen 443; server_name www.hellohttps1.com www.hellohttps2.com; set $geek_web_root &quot;/Users/doing/IdeaProjects/backend-geek-web&quot;; ssl_certificate /usr/local/etc/nginx/ssl-key/ssl.crt; #ssl证书文件位置(常见证书文件格式为：crt/pem) ssl_certificate_key /usr/local/etc/nginx/ssl-key/ssl.key; #ssl证书key位置 location /passport &#123; send_timeout 90; proxy_connect_timeout 50; proxy_send_timeout 90; proxy_read_timeout 90; proxy_pass http://https-svr; &#125; location ~ ^/(res|lib)/ &#123; root $geek_web_root; expires 7d;#add_header用于为后端服务器返回的response添加请求头，这里通过add_header实现CROS跨域请求服务器 add_header Access-Control-Allow-Origin *; &#125;#ssl配置参数（选择性配置） ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; &#125;#配置访问控制：每个IP一秒钟只处理一个请求，超出的请求会被delayed#语法：limit_req_zone $session_variable zone=name:size rate=rate (为session会话状态分配一个大小为size的内存存储区，限制了每秒（分、小时）只接受rate个IP的频率) limit_req_zone $binary_remote_addr zone=req_one:10m rate=1r/s nodelay; location /pay &#123; proxy_set_header Host $http_host; proxy_set_header X-Real_IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#访问控制：limit_req zone=name [burst=number] [nodelay]; limit_req zone=req_one burst=5; #burst=5表示超出的请求(被delayed)如果超过5个，那些请求会被终止（默认返回503） proxy_pass http://mysvr1; &#125;#可以把子配置文件放到/usr/local/etc/nginx/servers/路径下，通过include引入 include /usr/local/etc/nginx/servers/*.conf;&#125; 内置全局变量：123456789101112131415161718192021$args ：这个变量等于请求行中的参数，同$query_string$content_length ： 请求头中的Content-length字段。$content_type ： 请求头中的Content-Type字段。$document_root ： 当前请求在root指令中指定的值。$host ： 请求主机头字段，否则为服务器名称。$http_user_agent ： 客户端agent信息$http_cookie ： 客户端cookie信息$limit_rate ： 这个变量可以限制连接速率。$request_method ： 客户端请求的动作，通常为GET或POST。$remote_addr ： 客户端的IP地址。$remote_port ： 客户端的端口。$remote_user ： 已经经过Auth Basic Module验证的用户名。$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme ： HTTP方法（如http，https）。$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。$server_name ： 服务器名称。$server_port ： 请求到达服务器的端口号。$request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri ： 与$uri相同。 参考文章：http://blog.p2hp.com/archives/4493]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx基本原理]]></title>
    <url>%2F2017%2F08%2F04%2FNginx%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Nginx基本模块： Nginx 默认采用守护模式启动，守护模式让master进程启动后在后台运行。在Nginx运行期间主要由一个master主进程和多个worker进程 worker进程数目建议设为与cpu核数相同，这样每个worker进程都绑定特定的CPU核心，进程间切换的代价是最小的。因为一是Nginx一般做的是高并发代理，基本没有IO操作，大多数都是CPU密集型操作，很少出现IO阻塞等情况。二是进程与CPU调度的关系，单个核心处理多个进程的时候，是排队处理的，如果设置多个进程的时候，是排队处理的，如果设置多个进程时，会带来进程间切换的开销 master进程不会对用户请求提供服务，只用于管理真正提供服务的worker进程，所以master进程可以是唯一的，它仅专注于自己的纯管理工作，为管理员提供命令行服务，包括诸如启动服务、停止服务、重载配置文件、平滑升级程序等，当任意一个worker进程出现错误从而导致coredump时，master进程会立刻启动新的worker进程继续服务。 网络请求的处理，是放在worker进程中来完成的，而且只能在一个worker进程中处理。多个worker进程是相互独立且对等竞争的。采用这种方式的好处： 节省锁带来的开销。对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查上时，也会方便很多 独立进程，减少风险。采用独立的进程，可以让互相之间不会影响，当一个worker进程异常退出时，其它进程还在工作，服务不会中断，master进程则很快重新启动新的worker进程。虽然当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。 每个worker里面只有一个主线程，但一个worker可以同时处理多个请求。nginx采取异步非阻塞的方式处理请求，每个请求进来，worker线程将其注册处理转发给下游服务（如php-fpm）后，并不是挂起等待，而是切换处理别的请求。采用这种轮询的方式来并发处理大量请求 nginx的处理流程Nginx的IO通常使用epoll，epoll函数使用了I/O复用模型。与I/O阻塞模型比较，I/O复用模型的优势在于可以同时等待多个（而不只是一个）套接字描述符就绪。Nginx的epoll工作流程如下： 首先，master 进程接受到信号（如nginx -s reload）后启动，读取配置文件，建好需要listen的socket后，然后再fork出多个woker进程，这样每个work进程都可以去accept这个socket 2 . 当一个client连接到来时，所有accept的work进程都会受到通知，但只有一个进程可以accept成功，其它的则会accept失败，Nginx提供了一把共享锁accept_mutex来保证同一时刻只有一个work进程在accept连接，从而解决惊群问题 当一个worker进程accept这个连接后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完成的请求就结束了 一个worker进程可以同时处理多个请求，每个worker进程只有一个主线程，而是采用异步非阻塞的方式来处理并发请求。比如同时有多个http request的时候，worker主线程与第一条request建议连接将其处理转发给下游fast cgi后，并不会挂起等待，而是立马处理下一条，可以理解轮询处理。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换），更多的并发数，只是会占用更多的内存而已。因此nginx 是非常适合处理高并发请求的 惊群现象惊群现象：惊群效应就是当一个fd的事件被触发时，所有等待这个fd的线程或进程都被唤醒。一般都是socket的accept()会导致惊群，很多个进程都block在server socket的accept()，一但有客户端进来，所有进程的accept()都会返回，但是只有一个进程会读到数据，就是惊群。Nginx 采用accept-mutex来解决惊群问题：当一个请求到达的时候，只有竞争到锁的worker进程才会惊醒处理请求，其他进程会继续等待，结合 timer_solution 配置的最大的超时时间继续尝试获取accept-mutex 从I/O复用角度谈 nginx 和apache 的区别I/O 复用接口有select/poll 和 epoll ，首先介绍一下他们的执行方式： select/poll 模型：说的通俗一点就是各个客户端连接的文件描述符也就是套接字，都被放到了一个集合中，每次调用都要对 所有的socket进行一次线性扫描，如果有可读的描述符那么我们的工作进程就去读取资源。select()所维护的存储大量文件描述符的数据结构 ，随着文件描述符数量的增长，其在用户态和内核的地址空间的复制所引发的开销也会线性增长 epoll 模型：epoll 是 select 的增强版。epoll 文件描述符数量无限制。基于事件的就绪通知方式 ，select/poll方式，进程只有在调用一定的方法后，内核才会对所有监视的文件描述符进行扫描，而epoll事件通过epoll_ctl()注册一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似call back的回调机制，迅速激活这个文件描述符，epoll_wait()便会得到通知。 调用一次epoll_wait()获得就绪文件描述符时，返回的并不是实际的描述符，而是一个代表就绪描述符数量的值，拿到这些值去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里使用内存映射（mmap）技术， 避免了复制大量文件描述符带来的开销。 在select/poll时代，服务器进程每次都把这100万个连接告诉操作系统(从用户态复制句柄数据结构到内核态)，让操作系统内核去查询这些套接字上是否有事件发生，轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。epoll的设计和实现与select完全不同。epoll通过在Linux内核中申请一个简易的文件系统，把原先的select/poll调用分成了3个部分： 调用epoll_create()建立一个epoll对象(在epoll文件系统中为这个句柄对象分配资源)调用epoll_ctl向epoll对象中添加这100万个连接的套接字调用epoll_wait收集发生的事件的连接 只需要在进程启动时建立一个epoll对象，然后在需要的时候向这个epoll对象中添加或者删除连接。同时，epoll_wait的效率也非常高，因为调用epoll_wait时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接。 apache 采用的select模型，nginx采用epoll模型，nginx 处理请求是异步非阻塞的，而apache则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能。在Apache+PHP（prefork）模式下，如果PHP处理慢或者前端压力很大的情况下，很容易出现Apache进程数飙升，从而拒绝服务的现象。 Nginx 常用功能 Nginx支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。 Nginx作为Http代理、反向代理： Nginx通过配置实现灵活的转发功能：Nginx可以根据不同的正则匹配，采取不同的转发策略。 Nginx可以对返回结果进行错误页跳转，异常判断等。 如果被分发的服务器存在异常，它可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。 Nginx作为负载均衡器： Nginx提供的负载均衡策略有2种：内置策略和扩展策略。 内置策略为轮询，加权轮询，Ip hash。 扩展策略由第三方实现。 轮询与加权轮询： Ip hash算法，对客户端请求的ip进行hash操作，然后根据hash结果将同一个客户端ip的请求分发给同一台服务器进行处理，可以解决session不共享的问题。 Nginx作为Web缓存 可以把静态资源放在Nginx服务器上（比如前端页面资源） Nginx可以对不同的文件做不同的缓存处理，配置灵活。 配合着第三方的ngx_cache_purge，对指定的URL缓存内容可以的进行增删管理。 参考文章：http://tengine.taobao.org/book/chapter_02.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据库的事务隔离级别]]></title>
    <url>%2F2017%2F07%2F05%2FMySQL%E4%BA%8B%E5%8A%A1%E7%AD%89%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[数据库的事务隔离等级read uncommited不可避免脏读。 read commited可避免脏读，不可避免不可重复读。 repeated readmysql InnoDB默认级别的默认事务等级，不可以避免幻读。 serializable完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。 脏读:是指当前事务可以查看到别的事务未提交的数据（重点未提交）。 例如，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。 提交读，可以有效避免脏读。 不可重复读：是指一个事务内两次相同的查询却返回了不同结果集。 在一个事务内，多次读同一个数据。在这个事务还没有结束时，另一个事务也访问并修改该同一数据。造成第一个事务的两次读数据的结果不一样。 解决办法：如果只有在修改事务完全提交之后才可以读取数据。例如mysql行锁。 幻读：是指事务B以插入或删除行等方式来修改事务A查询搜索的结果集。 例如事务A查询表中是否存在id=1的数据，如不存在往表里则插入数据。而事务B则在事务A查询后插入前，往表里插入了一条id=1的数据，事务A之前的查询结果就无效，像出现幻觉一样。 这种情况在高并发情况下会出现，mysql的默认事务等级可重复读，不能避免，只有最高等级的SERIALIZABLE_READ可以保证不出现幻读的问题。例如表锁。 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引]]></title>
    <url>%2F2017%2F04%2F17%2FMySQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[关于MySQL索引（《高性能MySQL》阅读有感）B-Tree索引当我们讨论索引的时候，没有特别指明类型，多半是指的B-Tree索引。InnoDB引擎使用的B+Tree结构，按照原数据格式（MyISAM前缀压缩）进行存储，根据主键引用被索引的行（MyISAM根据物理位置）。 B-树意味着所有值都是按照顺序存储的，并且每个叶子页到根节点的距离相同。因为存储引擎不再需要进行全表扫描，只需要从索引根节点搜索，所以可以加快数据访问速度 局部性原理和磁盘预读由于磁盘的存取速度与内存之间鸿沟,为了提高效率,要尽量减少磁盘I/O.磁盘往往不是严格按需读取，而是每次都会预读,磁盘读取完需要的数据,会顺序向后读一定长度的数据放入内存。而这样做的理论依据是计算机科学中著名的局部性原理：12当一个数据被用到时，其附近的数据也通常会马上被使用程序运行期间所需要的数据通常比较集中 由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间)，因此对于具有局部性的程序来说，预读可以提高I/O效率.预读的长度一般为页(page)的整倍数。 什么是索引索引可以理解为目录，字典的搜索表。索引的本质就是排序。每建一个索引就相当于将增加一个包含主键和索引列的索引表，表中数据按照索引顺序排序。因为索引字段不宜过多，索引也不能滥用，否则会影响写表的性能。 聚簇索引和非聚簇索引 聚簇：索引的叶子节点指向数据 innodb 非聚簇：索引的叶子节点指向引用 myisam 对于innodb引擎，如果没有primary key，在用unique key作主键，如果没有unique，则mysql会生成一个rowid作主键 索引类型 主键索引 primary key 唯一索引 unique index 普通索引 index 全文索引 fulltext index 索引的使用原则前缀索引区分度区分度指字段在数据库的不重复比。区分度越大，索引效果越明显。在区分度较小的字段上新建索引，基本无效，还会增加大量的索引文件，得不偿失。 最左匹配原则MySQL会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配。缀索引在排序 order by 和分组 group by 操作的时候无法使用。 模糊查询前模糊是无法使用索引的，类似where c like ‘%a’。而like ‘a%’ 等价于 where c &gt;= ‘a’ and c &lt; ‘b’ 不能使用索引的场景 前模糊：例 like “%N” 隐式转换：例如name字段是varchar，而sql中where name=1而不是name=’1’ 函数运算不要在查询语句中加函数运算，否则索引失效。 不要滥用索引多余的索引会降低读写性能。即使满足了上述原则，mysql还是可能会弃用索引，因为有些查询即使使用索引，也会出现大量的随机io，相对于从数据记录中的顺序io开销更大。 EXPLAIN表扫描Handler_read_rnd_next 的值高则意味着查询运行低效，存在大量的表扫描，应该建立索引补救。 索引优化索引碎片与维护在数据表长期的更改过程中，索引文件和数据文件都会产生空洞，形成碎片。修复表的过程十分耗费资源，可以用比较长的周期修复表。1234//清理方法alert table xxx engine innodb; //或optimize table xxx;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 安装配置]]></title>
    <url>%2F2017%2F04%2F04%2FELK%2F</url>
    <content type="text"><![CDATA[Elasticsearch安装配置安装java81234//查看java版本java -version//安装javayum -y install java-1.8.0 下载Elasticsearch123456789//下载wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.4.2.zip//校验sha1sum elasticsearch-5.4.2.zip//解压sudo unzip -n elasticsearch-5.4.2.zip -d /usr/local////usr/local/elasticsearch-5.4.2 即为$ES_HOME//启动/usr/local/elasticsearch-5.4.2/bin/elasticsearch 常见错误1OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000085330000, 2060255232, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12) 错误原因：elasticsearch5.0默认分配jvm空间大小为2g 解决方案：修改jvm空间分配vim /usr/local/elasticsearch-5.4.2/config/jvm.options-Xms2g-Xmx2g修改为-Xms512m-Xmx512m 1can not run elasticsearch as root 错误原因：不能以root启动 解决方案：添加elasticsearch的用户并切换elasticsearch文件夹所属用户 12345678910111213141516171819202122groupadd esuseradd es -g es -p eschown -R es:es /usr/local/elasticsearch-5.4.2/sudo chown -R seclogin:users /usr/local/elasticsearch-5.4.2/max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536]vim /etc/security/limits.conf //修改或者添加如下* hard nofile 65536* soft nofile 65536max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]vim /etc/sysctl.conf//修改或者添加如下vm.max_map_count=262144//修改后sysctl -a，不起效就sysctl -p 1Failed to obtain node lock 解决方案：需要重启elasticsearch 12345//停止elasticsearchps -ef | grep elastickill -9 xxx//切换到 es用户再重新执行（seclogin用户不需要）su es -c /usr/local/elasticsearch-5.4.2/bin/elasticsearch 外部访问需以下配置12345678910111213141516vim /usr/local/elasticsearch-5.4.2/config/elasticsearch.ymlnetwork.host: 172.17.6.219 #本服务器ip//centos7以下需要修改iptablesvim /etc/sysconfig/iptables-A INPUT -p tcp -m state --state NEW -m tcp --dport 9200 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 9200 -j ACCEPTservice iptables restart//centos7需要修改firewall（如果没有防火墙就不用管了）firewall-cmd --permanent --add-port=9200/tcpfirewall-cmd --reloadfirewall-cmd --state//后台启动elasticsearch/usr/local/elasticsearch-5.4.2/bin/elasticsearch -d Elasticsearch测试及使用1234567891011121314151617181920212223242526272829303132333435363738//查看集群健康状态curl &apos;http://172.16.9.192:9200/_cat/health?v&apos; (dev)curl &apos;http://10.10.1.71:9200/_cat/health?v&apos; (test)curl &apos;http://10.1.2.56:9200/_cat/health?v&apos; (online)//查看 Elasticsearch 的基本信息curl &apos;http://172.16.9.192:9200/?pretty&apos; (dev)curl &apos;http://10.10.1.71:9200/?pretty&apos; (test)curl &apos;http://10.1.2.56:9200/?pretty&apos; (online)//列出所有索引curl &apos;http://172.16.9.192:9200/_cat/indices?v&apos; (dev)curl &apos;http://10.10.1.71:9200/_cat/indices?v&apos; (test)curl &apos;http://10.1.2.56:9200/_cat/indices?v&apos; (online)//添加一个名叫 test的索引（可理解为数据库）curl -XPUT &apos;http://172.16.9.192:9200/test?pretty&apos;curl -XPUT &apos;http://10.1.2.56:9200/test?pretty&apos;//查看索引curl &apos;http://101.200.42.161:9200/test?pretty&apos;//创建一个类型curl -XPUT &apos;http://101.200.42.161:9200/test/_mapping/article?pretty&apos; -d &apos;&#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125;, &quot;subject&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;standard&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;analyzer&quot;: &quot;standard&quot; &#125;, &quot;author&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot; &#125; &#125;&#125;&apos; 测试数据导入12wget https://github.com/bly2k/files/blob/master/accounts.zip?raw=truecurl -XPOST &apos;http://101.200.42.161::9200/bank/account/_bulk?pretty&apos; --data-binary @accounts.json Elasticsearch-PHP 配置https://www.elastic.co/guide/en/elasticsearch/client/php-api/5.0/_configuration.html 备注：elasticsearch默认最大查询数量是一万，test和online环境将最大查询数量提到了十万，设置命令：curl -XPUT http://10.1.2.56:9200/contentplatform/_settings -d ‘{ “index” : { “max_result_window” : 100000}}’]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识swoole]]></title>
    <url>%2F2017%2F02%2F07%2FSwoole%2F</url>
    <content type="text"><![CDATA[Server运行流程图 进程/线程结构图 创建TCP Server 示例代码12345678910111213141516171819202122//创建Server对象，监听 127.0.0.1:9501端口$serv = new swoole_server(&quot;127.0.0.1&quot;, 9501); //监听连接进入事件$serv-&gt;on(&apos;connect&apos;, function ($serv, $fd) &#123; echo &quot;Client: Connect.\n&quot;;&#125;);//服务器可以同时被成千上万个客户端连接，$fd就是客户端连接的唯一标识符//监听数据接收事件$serv-&gt;on(&apos;receive&apos;, function ($serv, $fd, $from_id, $data) &#123; $serv-&gt;send($fd, &quot;Server: &quot;.$data);&#125;);//监听连接关闭事件$serv-&gt;on(&apos;close&apos;, function ($serv, $fd) &#123; echo &quot;Client: Close.\n&quot;;&#125;);//启动服务器$serv-&gt;start(); ==swoole_server只能用于php-cli环境，否则会抛出致命错误。请勿在使用swoole_server之前调用其他异步IO的API，否则将无法创建swoole_server。== swoole_server是异步服务器，支持TCP、UDP、UnixSocket 3种协议，通过监听事件的方式来执行程序的。使用者无需关注底层实现细节，仅需要设置网络事件的回调函数即可。如当有新的TCP连接进入时会执行onConnect事件回调，当某个连接向服务器发送数据时会回调onReceive函数。客户端主动断开连接，会触发onClose事件回调。 构建Server对象1$serv = new swoole_server(&quot;127.0.0.1&quot;, 9501, SWOOLE_BASE, SWOOLE_SOCK_TCP); $mode运行的模式，swoole提供了3种运行模式，默认为多进程模式 $sock_type指定socket的类型，支持TCP/UDP、TCP6/UDP6、UnixSock Stream/Dgram 6种设置运行时参数 123456789$serv-&gt;set(array( &apos;reactor_num&apos; =&gt; 2, //通过此参数来调节poll线程的数量，以充分利用多核。reactor_num和writer_num默认设置为CPU核数 &apos;worker_num&apos; =&gt; 4, //设置启动的worker进程数量。swoole采用固定worker进程的模式。PHP代码中是全异步非阻塞，worker_num配置为CPU核数的1-4倍即可。如果是同步阻塞，worker_num配置为100或者更高 &apos;max_conn&apos; =&gt; 10000, //最大tcp连接 &apos;max_request&apos; =&gt; 50, //此参数表示worker进程在处理完n次请求后结束运行。manager会重新创建一个worker进程。此选项用来防止worker进程内存溢出。 &apos;daemonize&apos; =&gt; true, //守护进程化 &apos;backlog&apos; =&gt; 128, //Listen队列长度.此参数将决定最多同时有多少个待accept的连接，swoole本身accept效率是很高的，基本上不会出现大量排队情况。 &apos;log_file&apos; =&gt; &apos;/data/log/swoole.log&apos; //日志)); 属性列表123456$serv-&gt;setting; //set()函数所设置的参数会保存到$setting属性上。$serv-&gt;manager_pid; //管理进程的PID，通过向管理进程发送SIGUSR1信号可实现柔性重启$serv-&gt;master_pid; //主进程的PID，通过向主进程发送SIGTERM信号可安全关闭服务器$serv-&gt;worker_id; //得到当前Worker进程的编号，包括Task进程。$serv-&gt;worker_pid; //得到当前Worker进程的操作系统进程ID$serv-&gt;connections; //当前服务器的客户端连接，可使用foreach遍历所有连接 ==工作进程重启后worker_id的值是不变的== 注册事件回调函数12345$serv-&gt;on(&apos;Connect&apos;, &apos;my_onConnect&apos;);$serv-&gt;on(&apos;Receive&apos;, &apos;my_onReceive&apos;);$serv-&gt;on(&apos;Close&apos;, &apos;my_onClose&apos;);$serv-&gt;on(&apos;Task&apos;, &apos;my_onTask&apos;);//处理异步任务$serv-&gt;on(&apos;Finish&apos;, &apos;my_onFinish&apos;);//返回处理异步任务的结果 PHP中可以使用4种回调函数的风格,我个人比较倾向函数式。 编程须知： 在异步IO的程序中，不得使用sleep/usleep/time_sleep_until/time_nanosleep onReceive事件中执行了sleep函数，server在100秒内无法再收到任何客户端请求。 在swoole程序中禁止使用exit/die，如果PHP代码中有exit/die，当前工作的Worker进程、Task进程、User进程、以及swoole_process进程会立即退出。 建议使用try/catch的方式替换exit/die，实现中断执行跳出PHP函数调用栈。 Client同步阻塞客户端123456789101112131415161718192021$client = new swoole_client(SWOOLE_SOCK_TCP);//连接到服务器if (!$client-&gt;connect(&apos;127.0.0.1&apos;, 9501, 0.5))&#123; die(&quot;connect failed.&quot;);&#125;//向服务器发送数据if (!$client-&gt;send(&quot;hello world&quot;))&#123; die(&quot;send failed.&quot;);&#125;//从服务器接收数据$data = $client-&gt;recv();if (!$data)&#123; die(&quot;recv failed.&quot;);&#125;echo $data;//关闭连接$client-&gt;close(); 这个客户端是同步阻塞的，connect/send/recv 会等待IO完成后再返回。同步阻塞操作并不消耗CPU资源，IO操作未完成当前进程会自动转入sleep模式，当IO完成后操作系统会唤醒当前进程，继续向下执行代码。 异步非阻塞客户端123456789101112131415161718192021222324$client = new swoole_client(SWOOLE_SOCK_TCP, SWOOLE_SOCK_ASYNC);//注册连接成功回调$client-&gt;on(&quot;connect&quot;, function($cli) &#123; $cli-&gt;send(&quot;hello world\n&quot;);&#125;);//注册数据接收回调$client-&gt;on(&quot;receive&quot;, function($cli, $data)&#123; echo &quot;Received: &quot;.$data.&quot;\n&quot;;&#125;);//注册连接失败回调$client-&gt;on(&quot;error&quot;, function($cli)&#123; echo &quot;Connect failed\n&quot;;&#125;);//注册连接关闭回调$client-&gt;on(&quot;close&quot;, function($cli)&#123; echo &quot;Connection close\n&quot;;&#125;);//发起连接$client-&gt;connect(&apos;127.0.0.1&apos;, 9501, 0.5); ==异步客户端只能用于cli环境== 异步客户端是非阻塞的。可以用于编写高并发的程序。 异步客户端需要设置回调函数，4个事件回调必须设置onConnect、onError、onReceive、onClose。分别在客户端连接成功、连接失败、收到数据、连接关闭时触发。同步阻塞客户端一定不要使用on方法]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub搭建个人Blog]]></title>
    <url>%2F2015%2F10%2F06%2FHEXO%2F</url>
    <content type="text"><![CDATA[Hexo简介Hexo是一款基于Node.js的静态博客框架，可以方便的生成静态网页托管在GitHub和Heroku上。参见：Github地址 安装Git/Node.js依赖本地安装git、node.js。这个不赘述了。1234//git安装检测git --version//npm安装检测npm -v 安装Hexo12345678910//安装npm install hexo -g//初始化网站hexo init blog //新建bloghexo new test//生成静态文件hexo g//开启本地服务器hexo s 打开浏览器输入地址： localhost:4000 就能看到页面了。 更多相关命令参见：https://hexo.io/zh-cn/ 推送GitHubGitHub创建个人仓库 仓库名必须为：github账号名.github.io，固定写法，别问为啥。 本地生成ssh密钥文件：1ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot; 然后直接三个回车即可，默认不需要设置密码。然后vi ~/.ssh/id_rsa.pub文件，将内容全部复制 打开GitHub/Setting/SSH keys页面,new SSH Key标题随意，内容复制进入保存，输入 ssh git@github.com ：https://pic3.zhimg.com/80/v2-da481ffa686410becd4186c656b4ebd6_hd.jpg如上则说明成功 修改站点配置文件打开blog根目录下的_config.yml，翻到最后修改为：1234deploy: type: gitrepo: 这里填入你之前在GitHub上创建仓库的完整路径，记得加上 .gitbranch: master 然后输入1hexo g -d //生成并推送 然后在浏览器输入xxxx.github.io就可访问了。 更换主题主题传送门 我使用的NEXT主题：github地址 NEXT主题中文配置文档 NEXT主题去掉footer字样 绑定域名]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
